{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6034, 50, 50, 3)\n",
      "(6034, 63)\n",
      "(43377, 50, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "# Loading training image dataset\n",
    "trainset_features = np.load('train_images.pkl')\n",
    "train_labels = np.load('train_labels.pkl')\n",
    "test_features = np.load('test_images.pkl')\n",
    "\n",
    "# Normalizing the image data\n",
    "train_features = (trainset_features - np.min(trainset_features))/np.max(trainset_features)\n",
    "test_features = (test_features - np.min(test_features))/np.max(test_features)\n",
    "\n",
    "print(train_features.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_2d(x,W): \n",
    "    # Padding : surround the original image with 0's \n",
    "    # valid padding - no padding.size of the image shrinks  resultant image : (n - f + 1, n - f + 1)\n",
    "    # same padding - resultant is same as that of original. resultant image : (n + 2p - f + 1, n +2p - f + 1)  p = (f - 1)/2\n",
    "    # Strides : ((n + 2p - f)/s + 1, (n +2p - f)/s + 1)\n",
    "    return tf.nn.conv2d(input = x, filter = W, strides = [1,1,1,1], padding=\"SAME\")\n",
    "\n",
    "def avg_pool_2x2(x):\n",
    "    # MAX/AVG Pooling : ((n + 2p - f)/s + 1, (n +2p - f)/s + 1)\n",
    "    return tf.nn.avg_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "\n",
    "\n",
    "# Parameters and number of filters are the inspirations of AlexNet with little modifications\n",
    "def conv2_network(x_image): \n",
    "    \n",
    "    # First Conv and Pooling layers\n",
    "    W_conv1 = tf.Variable(tf.truncated_normal([5,5,3,8], stddev=0.02))\n",
    "    b_conv1 = tf.Variable(tf.zeros([8]))\n",
    "    h_conv1 = tf.nn.relu(conv_2d(x_image, W_conv1) + b_conv1)\n",
    "    h_pool1 = avg_pool_2x2(h_conv1)\n",
    "    conv1 = tf.nn.dropout(h_pool1, keep_prob)\n",
    "\n",
    "    # Seond Conv and Pooling layers\n",
    "    W_conv2 = tf.Variable(tf.truncated_normal([5,5,8,32], stddev=0.02)) \n",
    "    b_conv2 = tf.Variable(tf.zeros([32]))\n",
    "    h_conv2 = tf.nn.relu(conv_2d(conv1, W_conv2) + b_conv2)\n",
    "    h_pool2 = avg_pool_2x2(h_conv2)\n",
    "    conv2 = tf.nn.dropout(h_pool2, keep_prob)\n",
    "\n",
    "    #Flattenning the output of ConvNets \n",
    "    flat_conv2 = tf.contrib.layers.flatten(conv2)\n",
    "\n",
    "    # First fully connected layers\n",
    "    datasize = flat_conv2.get_shape().as_list()[1]\n",
    "    W_fc1 = tf.Variable(tf.truncated_normal([datasize, 64], stddev=0.02))\n",
    "    b_fc1 = tf.Variable(tf.zeros([64]))\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(flat_conv2,W_fc1)+b_fc1)\n",
    "    h_fc1 = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "    # Output layer\n",
    "    y_conv = tf.layers.dense(inputs=h_fc1, units=63)\n",
    "    return y_conv\n",
    "\n",
    "def batches(batch_size, features, labels):\n",
    "    assert len(features) == len(labels)\n",
    "    out_batches = []\n",
    "    sample_size = len(features)\n",
    "    for start_i in range(0, sample_size, batch_size):\n",
    "        end_i = start_i + batch_size\n",
    "        batches = [features[start_i:end_i], labels[start_i:end_i]] \n",
    "        out_batches.append(batches)\n",
    "    return out_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0   - Training Accuracy: 0.0\n",
      "Epoch 10  - Training Accuracy: 0.0\n",
      "Epoch 20  - Training Accuracy: 0.0\n",
      "Epoch 30  - Training Accuracy: 0.0555555559694767\n",
      "Epoch 40  - Training Accuracy: 0.0\n",
      "Epoch 50  - Training Accuracy: 0.0555555559694767\n",
      "Epoch 60  - Training Accuracy: 0.0555555559694767\n",
      "Epoch 70  - Training Accuracy: 0.0555555559694767\n",
      "Epoch 80  - Training Accuracy: 0.0\n",
      "Epoch 90  - Training Accuracy: 0.0\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "n_channels = 3 \n",
    "n_classes = 63\n",
    "im_size = 50\n",
    "\n",
    "# Features and Labels\n",
    "features = tf.placeholder(tf.float32, [None, im_size, im_size, n_channels])\n",
    "labels = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(dtype=tf.float32, name = \"keep_prob\")\n",
    "\n",
    "# Learning rate \n",
    "learning_rate = 0.01\n",
    "\n",
    "# Output of the model \n",
    "output = conv2_network(features)\n",
    "\n",
    "# Calculating cost\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = output, labels = labels))\n",
    "# Optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(output,1), tf.argmax(labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Train or test with this batch size\n",
    "batchSize =  128 \n",
    "epochs = 100\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer() \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init) \n",
    "    train_batches = batches(batchSize, train_features, train_labels)\n",
    "    \n",
    "    for epoch in range(epochs): \n",
    "        for batch_features, batch_labels in train_batches: \n",
    "            train_data = {features: batch_features, labels : batch_labels, keep_prob : 0.7}\n",
    "            training_accuracy = sess.run(accuracy, feed_dict = train_data )\n",
    "            # Print status for every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            print('Epoch {:<3} - Training Accuracy: {}'.format(epoch,training_accuracy))\n",
    "\n",
    "    # Save the variables to disk.\n",
    "    save_model_path = './image_classification'\n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
